{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Model Fine-tuning\n",
    "In this notebook, you'll fine-tune the Meta Llama 2 7B large language model, deploy the fine-tuned model, and test it's text generation and domain knowledge capabilities. \n",
    "\n",
    "Fine-tuning refers to the process of taking a pre-trained language model and retraining it for a different but related task using specific data. This approach is also known as transfer learning, which involves transferring the knowledge learned from one task to another. Large language models (LLMs) like Llama 2 7B are trained on massive amounts of unlabeled data and can be fine-tuned on domain domain datasets, making the model perform better on that specific domain.\n",
    "\n",
    "Input: A train and an optional validation directory. Each directory contains a CSV/JSON/TXT file.\n",
    "For CSV/JSON files, the train or validation data is used from the column called 'text' or the first column if no column called 'text' is found.\n",
    "The number of files under train and validation should equal to one.\n",
    "\n",
    "- **You'll choose your dataset below based on the domain you've chosen**\n",
    "\n",
    "Output: A trained model that can be deployed for inference.\\\n",
    "After you've fine-tuned the model, you'll evaluate it with the same input you used in project step 2: model evaluation. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up\n",
    "\n",
    "---\n",
    "Install and import the necessary packages. Restart the kernel after executing the cell below. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.232.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker) (23.2.0)\n",
      "Collecting boto3<2.0,>=1.34.142 (from sagemaker)\n",
      "  Downloading boto3-1.35.28-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting cloudpickle==2.2.1 (from sagemaker)\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting docker (from sagemaker)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: google-pasta in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker) (0.2.0)\n",
      "Collecting importlib-metadata<7.0,>=1.4.0 (from sagemaker)\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: jsonschema in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker) (4.22.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/malhar.inamdar/Library/Python/3.12/lib/python/site-packages (from sagemaker) (24.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker) (2.2.1)\n",
      "Collecting pathos (from sagemaker)\n",
      "  Downloading pathos-0.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: platformdirs in /Users/malhar.inamdar/Library/Python/3.12/lib/python/site-packages (from sagemaker) (4.2.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: psutil in /Users/malhar.inamdar/Library/Python/3.12/lib/python/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker) (2.31.0)\n",
      "Collecting sagemaker-core<2.0.0,>=1.0.0 (from sagemaker)\n",
      "  Downloading sagemaker_core-1.0.9-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting schema (from sagemaker)\n",
      "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting smdebug-rulesconfig==1.0.1 (from sagemaker)\n",
      "  Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting tblib<4,>=1.7.0 (from sagemaker)\n",
      "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker) (4.66.4)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests (from sagemaker)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.24.2)\n",
      "Collecting botocore<1.36.0,>=1.35.28 (from boto3<2.0,>=1.34.142->sagemaker)\n",
      "  Downloading botocore-1.35.28-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0,>=1.34.142->sagemaker)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0,>=1.34.142->sagemaker)\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.22.0->datasets) (4.11.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7.0,>=1.4.0->sagemaker)\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->sagemaker) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->sagemaker) (2024.2.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker) (13.7.1)\n",
      "Collecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.0->sagemaker)\n",
      "  Downloading mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema->sagemaker) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema->sagemaker) (0.18.1)\n",
      "Requirement already satisfied: six in /Users/malhar.inamdar/Library/Python/3.12/lib/python/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/malhar.inamdar/Library/Python/3.12/lib/python/site-packages (from pandas->sagemaker) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Collecting ppft>=1.7.6.8 (from pathos->sagemaker)\n",
      "  Downloading ppft-1.7.6.8-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pox>=0.3.4 (from pathos->sagemaker)\n",
      "  Downloading pox-0.3.4-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (2.20.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/malhar.inamdar/Library/Python/3.12/lib/python/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker) (0.1.2)\n",
      "Downloading sagemaker-2.232.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading smdebug_rulesconfig-1.0.1-py2.py3-none-any.whl (20 kB)\n",
      "Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "Downloading boto3-1.35.28-py3-none-any.whl (139 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading sagemaker_core-1.0.9-py3-none-any.whl (384 kB)\n",
      "Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pathos-0.3.2-py3-none-any.whl (82 kB)\n",
      "Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading botocore-1.35.28-py3-none-any.whl (12.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Downloading pox-0.3.4-py3-none-any.whl (29 kB)\n",
      "Downloading ppft-1.7.6.8-py3-none-any.whl (56 kB)\n",
      "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: schema, zipp, xxhash, tblib, smdebug-rulesconfig, requests, ppft, pox, mock, jmespath, dill, cloudpickle, multiprocess, importlib-metadata, docker, botocore, s3transfer, pathos, datasets, boto3, sagemaker-core, sagemaker\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 3.0.0\n",
      "    Uninstalling cloudpickle-3.0.0:\n",
      "      Successfully uninstalled cloudpickle-3.0.0\n",
      "Successfully installed boto3-1.35.28 botocore-1.35.28 cloudpickle-2.2.1 datasets-3.0.1 dill-0.3.8 docker-7.1.0 importlib-metadata-6.11.0 jmespath-1.0.1 mock-4.0.3 multiprocess-0.70.16 pathos-0.3.2 pox-0.3.4 ppft-1.7.6.8 requests-2.32.3 s3transfer-0.10.2 sagemaker-2.232.1 sagemaker-core-1.0.9 schema-0.7.7 smdebug-rulesconfig-1.0.1 tblib-3.0.0 xxhash-3.5.0 zipp-3.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade sagemaker datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the model to fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id, model_version = \"meta-textgeneration-llama-2-7b\", \"2.*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, choose the training dataset text for the domain you've chosen and update the code in the cell below:  \n",
    "\n",
    "To create a finance domain expert model: \n",
    "\n",
    "- `\"training\": f\"s3://genaiwithawsproject2024/training-datasets/finance\"`\n",
    "\n",
    "To create a medical domain expert model: \n",
    "\n",
    "- `\"training\": f\"s3://genaiwithawsproject2024/training-datasets/medical\"`\n",
    "\n",
    "To create an IT domain expert model: \n",
    "\n",
    "- `\"training\": f\"s3://genaiwithawsproject2024/training-datasets/it\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "import boto3\n",
    "\n",
    "estimator = JumpStartEstimator(model_id=model_id,  environment={\"accept_eula\": \"true\"},instance_type = \"ml.g5.2xlarge\") \n",
    "\n",
    "estimator.set_hyperparameters(instruction_tuned=\"False\", epoch=\"5\")\n",
    "\n",
    "#Fill in the code below with the dataset you want to use from above \n",
    "#example: estimator.fit({\"training\": f\"s3://genaiwithawsproject2024/training-datasets/finance\"})\n",
    "estimator.fit({ \"training\": f\"s3://genaiwithawsproject2024/training-datasets/medical\" })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy the fine-tuned model\n",
    "---\n",
    "Next, we deploy the domain fine-tuned model. We will compare the performance of the fine-tuned and pre-trained model.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Do not use estimator.deploy() without mentioning the instance_type. \n",
    "# It's because when you call estimator.deploy() without explicitly setting the instance_type for the endpoint, \n",
    "# SageMaker selects a default instance type for hosting, which, in this case, is ml.g5.12xlarge.\n",
    "# However, Udacity doesn't allow instance type more than \"ml.*.2xlarge\". \n",
    "'''\n",
    "finetuned_predictor = estimator.deploy(instance_type=\"ml.g5.2xlarge\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the pre-trained and fine-tuned model\n",
    "---\n",
    "Next, we use the same input from the model evaluation step to evaluate the performance of the fine-tuned model and compare it with the base pre-trained model. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to print the response from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(payload, response):\n",
    "    print(payload[\"inputs\"])\n",
    "    print(f\"> {response}\")\n",
    "    print(\"\\n==================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the same prompts on the fine-tuned model to evaluate it's domain knowledge.   \n",
    "\n",
    "**Replace \"inputs\"** in the next cell with the input to send the model based on the domain you've chosen. \n",
    "\n",
    "**For financial domain:**\n",
    "\n",
    "  \"inputs\": \"Replace with sentence below from text\"  \n",
    "- \"The  investment  tests  performed  indicate\"\n",
    "- \"the  relative  volume  for  the  long  out  of  the  money  options, indicates\"\n",
    "- \"The  results  for  the  short  in  the  money  options\"\n",
    "- \"The  results  are  encouraging  for  aggressive  investors\"\n",
    "\n",
    "**For medical domain:** \n",
    "\n",
    "  \"inputs\": \"Replace with sentence below from text\" \n",
    "- \"Myeloid neoplasms and acute leukemias derive from\"\n",
    "- \"Genomic characterization is essential for\"\n",
    "- \"Certain germline disorders may be associated with\"\n",
    "- \"In contrast to targeted approaches, genome-wide sequencing\"\n",
    "\n",
    "**For IT domain:** \n",
    "\n",
    "  \"inputs\": \"Replace with sentence below from text\" \n",
    "- \"Traditional approaches to data management such as\"\n",
    "- \"A second important aspect of ubiquitous computing environments is\"\n",
    "- \"because ubiquitous computing is intended to\" \n",
    "- \"outline the key aspects of ubiquitous computing from a data management perspective.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"inputs\": \"Domain specific input chosen from above\",\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 64,\n",
    "        \"top_p\": 0.9,\n",
    "        \"temperature\": 0.6,\n",
    "        \"return_full_text\": False,\n",
    "    },\n",
    "}\n",
    "try:\n",
    "    response = finetuned_predictor.predict(payload, custom_attributes=\"accept_eula=true\")\n",
    "    print_response(payload, response)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the outputs from the fine-tuned model provide domain-specific insightful and relevant content? You can continue experimenting with the inputs of the model to test it's domain knowledge. \n",
    "\n",
    "**Use the output from this notebook to fill out the \"model fine-tuning\" section of the project documentation report**\n",
    "\n",
    "**After you've filled out the report, run the cells below to delete the model deployment** \n",
    "\n",
    "`IF YOU FAIL TO RUN THE CELLS BELOW YOU WILL RUN OUT OF BUDGET TO COMPLETE THE PROJECT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_predictor.delete_model()\n",
    "finetuned_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
